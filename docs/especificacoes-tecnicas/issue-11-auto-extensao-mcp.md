# Especifica√ß√£o T√©cnica - Sistema Base de Auto-Extens√£o MCP

## üéØ Vis√£o Geral

Esta especifica√ß√£o detalha a implementa√ß√£o do sistema core do SkyHAL que permitir√° auto-identifica√ß√£o de limita√ß√µes e auto-cria√ß√£o de novas tools para super√°-las. O sistema ser√° baseado nos princ√≠pios da Clean Architecture, seguindo os padr√µes de desenvolvimento Python MCP, com foco em seguran√ßa, observabilidade e extensibilidade.

## üìã Artefatos Afetados/Criados

### 1. Arquitetura do Sistema
**Arquivo:** `docs/especificacoes-tecnicas/issue-11-auto-extensao-mcp.md`

### 2. Core do Sistema de Auto-Extens√£o
**Diret√≥rio:** `src/domain/auto_extension/`
**Arquivos:**
- `__init__.py`
- `capability_analyzer.py`
- `tool_generator.py`
- `tool_validator.py`
- `learning_system.py`
- `entities/`

### 3. Servi√ßos de Aplica√ß√£o
**Diret√≥rio:** `src/application/auto_extension/`
**Arquivos:**
- `__init__.py`
- `capability_analysis_service.py`
- `tool_generation_service.py`
- `learning_service.py`

### 4. Infraestrutura
**Diret√≥rio:** `src/infrastructure/auto_extension/`
**Arquivos:**
- `__init__.py`
- `sandbox/`
- `repositories/`
- `security/`

### 5. API e Apresenta√ß√£o
**Diret√≥rio:** `src/presentation/api/routers/`
**Arquivos:**
- `auto_extension.py`

### 6. Testes
**Diret√≥rio:** `tests/`
**Arquivos em:**
- `tests/unit/domain/auto_extension/`
- `tests/unit/application/auto_extension/`
- `tests/integration/auto_extension/`

### 7. Observabilidade
**Diret√≥rio:** `src/infrastructure/observability/`
**Arquivos:**
- `auto_extension_metrics.py`
- `auto_extension_traces.py`

### 8. Documenta√ß√£o
**Diret√≥rios:**
- `docs/auto_extension/`
- `docs/especificacoes-tecnicas/artefatos/`

## üìù Especifica√ß√µes T√©cnicas Detalhadas

### 1. Arquitetura do Sistema

**Arquivo:** `docs/especificacoes-tecnicas/issue-11-auto-extensao-mcp.md`

**Descri√ß√£o:** Documento que detalha a arquitetura geral do sistema de auto-extens√£o, incluindo componentes, fluxos, interfaces e considera√ß√µes de seguran√ßa.

**Conte√∫do:**
- Vis√£o geral da arquitetura
- Diagrama de componentes
- Fluxos de comunica√ß√£o
- Interfaces e contratos
- Considera√ß√µes de seguran√ßa
- Mecanismos de fallback
- Estrat√©gia de observabilidade
- Evolu√ß√£o futura

**Instructions Relacionadas:**
- `global.instructions.md`: Diretrizes gerais de arquitetura
- `documentation.instructions.md`: Padr√µes de documenta√ß√£o
- `memory-bank.instructions.md`: Integra√ß√£o com Memory Bank

**Prompts Relacionados:**
- `sequential-planning.prompt.md`: Para planejamento estruturado
- `memory-analysis.prompt.md`: Para an√°lise de contexto

**Chat Mode Recomendado:**
- `arquiteto.chatmode.md`: Para defini√ß√£o da arquitetura

### 2. Sistema de An√°lise de Capacidades

**Diret√≥rio:** `src/domain/auto_extension/`
**Arquivo Principal:** `capability_analyzer.py`

**Descri√ß√£o:** Componente respons√°vel por analisar as capacidades atuais do sistema, identificar limita√ß√µes e √°reas para melhoria.

**Funcionalidades Principais:**
- Detec√ß√£o de limita√ß√µes atuais baseada em feedback e m√©tricas
- Classifica√ß√£o de tipos de tarefas que precisam de melhoria
- An√°lise de performance por tipo de tarefa
- Gera√ß√£o de recomenda√ß√µes para novas tools

**Exemplo de Implementa√ß√£o:**
```python
from dataclasses import dataclass
from typing import List, Dict, Any, Optional
from enum import Enum

class CapabilityType(Enum):
    DATA_PROCESSING = "data_processing"
    TEXT_GENERATION = "text_generation"
    CODE_ANALYSIS = "code_analysis"
    EXTERNAL_INTEGRATION = "external_integration"
    REASONING = "reasoning"

@dataclass
class CapabilityGap:
    """Representa uma lacuna identificada nas capacidades atuais."""
    capability_type: CapabilityType
    description: str
    severity: float  # 0.0 a 1.0
    frequency: float  # 0.0 a 1.0
    examples: List[str]
    potential_solutions: List[str]

class CapabilityAnalyzer:
    """Analisador de capacidades do sistema."""

    def __init__(self, metrics_provider, feedback_provider):
        self.metrics_provider = metrics_provider
        self.feedback_provider = feedback_provider
        self.logger = setup_logger(__name__)

    async def analyze_capabilities(self) -> List[CapabilityGap]:
        """Analisa capacidades atuais e identifica lacunas."""
        try:
            metrics = await self.metrics_provider.get_performance_metrics()
            feedback = await self.feedback_provider.get_recent_feedback()

            # An√°lise de m√©tricas e feedback
            gaps = self._identify_gaps(metrics, feedback)

            self.logger.info(
                "capability_analysis_completed",
                gaps_found=len(gaps),
                severity_avg=sum(gap.severity for gap in gaps) / len(gaps) if gaps else 0
            )

            return gaps
        except Exception as e:
            self.logger.error("capability_analysis_failed", exc_info=e)
            raise

    def _identify_gaps(self, metrics: Dict[str, Any], feedback: List[Dict[str, Any]]) -> List[CapabilityGap]:
        # Implementa√ß√£o da l√≥gica de identifica√ß√£o de lacunas
        # ...
```

**Instructions Relacionadas:**
- `python-mcp.instructions.md`: Padr√µes de desenvolvimento Python
- `observabilidade.instructions.md`: Integra√ß√£o de m√©tricas e logs

**Prompts Relacionados:**
- `entity-management.prompt.md`: Para modelagem de entidades de dom√≠nio

### 3. Gerador de Tools

**Diret√≥rio:** `src/domain/auto_extension/`
**Arquivo Principal:** `tool_generator.py`

**Descri√ß√£o:** Componente respons√°vel por gerar novas tools baseadas nas lacunas identificadas pelo analisador de capacidades.

**Funcionalidades Principais:**
- Template engine para cria√ß√£o de novas tools
- Gera√ß√£o de c√≥digo baseado em especifica√ß√µes
- Integra√ß√£o com sandbox para teste seguro
- Sistema de vers√µes para tools geradas

**Exemplo de Implementa√ß√£o:**
```python
from dataclasses import dataclass
from typing import Dict, Any, List, Optional
import uuid

@dataclass
class ToolSpec:
    """Especifica√ß√£o para gera√ß√£o de uma nova tool."""
    name: str
    description: str
    parameters: Dict[str, Any]
    return_type: str
    template_id: str
    security_level: str
    resource_requirements: Dict[str, Any]

@dataclass
class GeneratedTool:
    """Resultado da gera√ß√£o de uma nova tool."""
    tool_id: str
    name: str
    code: str
    spec: ToolSpec
    validation_results: Dict[str, Any]
    version: str
    created_at: str

class ToolGenerator:
    """Gerador de novas tools baseado em especifica√ß√µes."""

    def __init__(self, template_provider, code_generator, security_validator):
        self.template_provider = template_provider
        self.code_generator = code_generator
        self.security_validator = security_validator
        self.logger = setup_logger(__name__)

    async def generate_tool(self, spec: ToolSpec) -> GeneratedTool:
        """Gera uma nova tool baseada na especifica√ß√£o."""
        try:
            # Validar especifica√ß√£o
            self._validate_spec(spec)

            # Obter template
            template = await self.template_provider.get_template(spec.template_id)

            # Gerar c√≥digo
            code = await self.code_generator.generate(template, spec)

            # Validar seguran√ßa
            validation_results = await self.security_validator.validate(code, spec)

            # Criar tool
            tool = GeneratedTool(
                tool_id=str(uuid.uuid4()),
                name=spec.name,
                code=code,
                spec=spec,
                validation_results=validation_results,
                version="1.0.0",
                created_at=datetime.utcnow().isoformat()
            )

            self.logger.info(
                "tool_generated",
                tool_id=tool.tool_id,
                name=tool.name,
                validation_status="success" if validation_results["passed"] else "failed"
            )

            return tool
        except Exception as e:
            self.logger.error("tool_generation_failed", spec_name=spec.name, exc_info=e)
            raise

    def _validate_spec(self, spec: ToolSpec) -> None:
        # Implementa√ß√£o da valida√ß√£o de especifica√ß√£o
        # ...
```

**Instructions Relacionadas:**
- `python-mcp.instructions.md`: Padr√µes de desenvolvimento Python
- `api-security.instructions.md`: Seguran√ßa em desenvolvimento

**Prompts Relacionados:**
- `code-generation.prompt.md`: Para gera√ß√£o de c√≥digo seguro

### 4. Sistema de Valida√ß√£o de Tools

**Diret√≥rio:** `src/domain/auto_extension/`
**Arquivo Principal:** `tool_validator.py`

**Descri√ß√£o:** Componente respons√°vel por validar e testar as tools geradas antes de sua integra√ß√£o ao sistema.

**Funcionalidades Principais:**
- Valida√ß√£o de seguran√ßa e permiss√µes
- Testes automatizados em sandbox
- Verifica√ß√£o de conformidade com contratos
- An√°lise est√°tica de c√≥digo

**Exemplo de Implementa√ß√£o:**
```python
from dataclasses import dataclass
from typing import Dict, Any, List, Optional
from enum import Enum

class ValidationResult(Enum):
    PASSED = "passed"
    FAILED_SECURITY = "failed_security"
    FAILED_FUNCTIONALITY = "failed_functionality"
    FAILED_PERFORMANCE = "failed_performance"
    FAILED_COMPATIBILITY = "failed_compatibility"

@dataclass
class ValidationReport:
    """Relat√≥rio detalhado da valida√ß√£o de uma tool."""
    tool_id: str
    result: ValidationResult
    security_score: float  # 0.0 a 1.0
    performance_score: float  # 0.0 a 1.0
    test_results: Dict[str, Any]
    issues: List[Dict[str, Any]]
    recommendations: List[str]

class ToolValidator:
    """Validador de tools geradas."""

    def __init__(self, sandbox_provider, security_analyzer, test_runner):
        self.sandbox_provider = sandbox_provider
        self.security_analyzer = security_analyzer
        self.test_runner = test_runner
        self.logger = setup_logger(__name__)

    async def validate_tool(self, tool: GeneratedTool) -> ValidationReport:
        """Valida uma tool gerada em ambiente sandbox."""
        try:
            # An√°lise de seguran√ßa
            security_results = await self.security_analyzer.analyze(tool.code)

            # Preparar sandbox
            sandbox = await self.sandbox_provider.create_sandbox()

            # Executar testes
            with tracer.start_as_current_span("tool_validation_tests") as span:
                span.set_attribute("tool_id", tool.tool_id)
                test_results = await self.test_runner.run_tests(sandbox, tool)

            # An√°lise dos resultados
            result, issues, recommendations = self._analyze_results(security_results, test_results)

            # Criar relat√≥rio
            report = ValidationReport(
                tool_id=tool.tool_id,
                result=result,
                security_score=security_results["score"],
                performance_score=test_results.get("performance_score", 0.0),
                test_results=test_results,
                issues=issues,
                recommendations=recommendations
            )

            self.logger.info(
                "tool_validation_completed",
                tool_id=tool.tool_id,
                result=result.value,
                security_score=security_results["score"],
                issues_count=len(issues)
            )

            return report
        except Exception as e:
            self.logger.error("tool_validation_failed", tool_id=tool.tool_id, exc_info=e)
            raise
        finally:
            # Limpar sandbox
            await self.sandbox_provider.destroy_sandbox(sandbox)

    def _analyze_results(self, security_results, test_results):
        # Implementa√ß√£o da an√°lise de resultados
        # ...
```

**Instructions Relacionadas:**
- `test.instructions.md`: Padr√µes de testes
- `api-security.instructions.md`: Seguran√ßa em desenvolvimento

**Prompts Relacionados:**
- `generate-tests.prompt.md`: Para gera√ß√£o de testes automatizados
- `security-analysis.prompt.md`: Para an√°lise de seguran√ßa

### 5. Sistema de Auto-Aprendizado

**Diret√≥rio:** `src/domain/auto_extension/`
**Arquivo Principal:** `learning_system.py`

**Descri√ß√£o:** Componente respons√°vel pelo aprendizado cont√≠nuo baseado no uso e feedback das tools criadas.

**Funcionalidades Principais:**
- Coleta de m√©tricas de uso de tools
- An√°lise de efetividade
- Ajuste autom√°tico de par√¢metros
- Identifica√ß√£o de padr√µes de uso

**Exemplo de Implementa√ß√£o:**
```python
from dataclasses import dataclass
from typing import Dict, Any, List, Optional
import time

@dataclass
class ToolUsageMetrics:
    """M√©tricas de uso de uma tool."""
    tool_id: str
    invocation_count: int
    success_rate: float
    average_execution_time: float
    error_types: Dict[str, int]
    user_ratings: List[float]
    last_used_at: float

@dataclass
class LearningInsight:
    """Insight gerado pelo sistema de aprendizado."""
    tool_id: str
    suggested_improvements: List[str]
    parameter_adjustments: Dict[str, Any]
    usage_patterns: Dict[str, Any]
    performance_bottlenecks: List[str]

class LearningSystem:
    """Sistema de auto-aprendizado baseado em uso de tools."""

    def __init__(self, metrics_collector, pattern_analyzer):
        self.metrics_collector = metrics_collector
        self.pattern_analyzer = pattern_analyzer
        self.logger = setup_logger(__name__)

    async def analyze_tool_usage(self, tool_id: str) -> LearningInsight:
        """Analisa o uso de uma tool e gera insights."""
        try:
            # Coletar m√©tricas de uso
            with tracer.start_as_current_span("collect_tool_metrics") as span:
                span.set_attribute("tool_id", tool_id)
                metrics = await self.metrics_collector.get_tool_metrics(tool_id)

            # Identificar padr√µes
            usage_patterns = await self.pattern_analyzer.identify_patterns(metrics)

            # Gerar sugest√µes de melhoria
            suggestions = self._generate_suggestions(metrics, usage_patterns)

            # Calcular ajustes de par√¢metros
            parameter_adjustments = self._calculate_parameter_adjustments(metrics, usage_patterns)

            # Identificar gargalos de performance
            bottlenecks = self._identify_bottlenecks(metrics)

            # Criar insight
            insight = LearningInsight(
                tool_id=tool_id,
                suggested_improvements=suggestions,
                parameter_adjustments=parameter_adjustments,
                usage_patterns=usage_patterns,
                performance_bottlenecks=bottlenecks
            )

            self.logger.info(
                "tool_learning_analysis_completed",
                tool_id=tool_id,
                suggestions_count=len(suggestions),
                bottlenecks_count=len(bottlenecks)
            )

            return insight
        except Exception as e:
            self.logger.error("tool_learning_analysis_failed", tool_id=tool_id, exc_info=e)
            raise

    def _generate_suggestions(self, metrics: ToolUsageMetrics, usage_patterns: Dict[str, Any]) -> List[str]:
        # Implementa√ß√£o da gera√ß√£o de sugest√µes
        # ...

    def _calculate_parameter_adjustments(self, metrics: ToolUsageMetrics, usage_patterns: Dict[str, Any]) -> Dict[str, Any]:
        # Implementa√ß√£o do c√°lculo de ajustes
        # ...

    def _identify_bottlenecks(self, metrics: ToolUsageMetrics) -> List[str]:
        # Implementa√ß√£o da identifica√ß√£o de gargalos
        # ...
```

**Instructions Relacionadas:**
- `python-mcp.instructions.md`: Padr√µes de desenvolvimento Python
- `observabilidade.instructions.md`: Integra√ß√£o de m√©tricas e logs

**Prompts Relacionados:**
- `performance-optimization.prompt.md`: Para otimiza√ß√£o de performance

### 6. Sandbox de Seguran√ßa

**Diret√≥rio:** `src/infrastructure/auto_extension/sandbox/`
**Arquivos Principais:**
- `__init__.py`
- `container_sandbox.py`
- `memory_sandbox.py`
- `permission_manager.py`

**Descri√ß√£o:** Implementa√ß√£o de ambiente isolado para execu√ß√£o segura de tools geradas, com controle de acesso a recursos e monitoramento.

**Funcionalidades Principais:**
- Isolamento de execu√ß√£o
- Controle de recursos (mem√≥ria, CPU)
- Monitoramento de opera√ß√µes
- Gest√£o de permiss√µes
- Timeout e interrup√ß√£o de execu√ß√µes

**Exemplo de Implementa√ß√£o:**
```python
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
import asyncio
import resource
import uuid

class Sandbox(ABC):
    """Interface para ambientes sandbox de execu√ß√£o."""

    @abstractmethod
    async def initialize(self) -> str:
        """Inicializa o ambiente sandbox e retorna ID."""
        pass

    @abstractmethod
    async def execute(self, sandbox_id: str, code: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """Executa c√≥digo no sandbox com os par√¢metros fornecidos."""
        pass

    @abstractmethod
    async def destroy(self, sandbox_id: str) -> None:
        """Destr√≥i o ambiente sandbox."""
        pass

class MemorySandbox(Sandbox):
    """Implementa√ß√£o de sandbox em mem√≥ria com isolamento de recursos."""

    def __init__(self, permission_manager, resource_limiter):
        self.permission_manager = permission_manager
        self.resource_limiter = resource_limiter
        self.sandboxes = {}
        self.logger = setup_logger(__name__)

    async def initialize(self) -> str:
        """Inicializa um novo sandbox em mem√≥ria."""
        try:
            sandbox_id = str(uuid.uuid4())

            # Criar ambiente isolado
            self.sandboxes[sandbox_id] = {
                "created_at": time.time(),
                "namespace": {},
                "permissions": self.permission_manager.get_default_permissions(),
                "resources": self.resource_limiter.get_default_limits()
            }

            self.logger.info(
                "sandbox_initialized",
                sandbox_id=sandbox_id
            )

            return sandbox_id
        except Exception as e:
            self.logger.error("sandbox_initialization_failed", exc_info=e)
            raise

    async def execute(self, sandbox_id: str, code: str, params: Dict[str, Any]) -> Dict[str, Any]:
        """Executa c√≥digo no sandbox com isolamento e limites."""
        if sandbox_id not in self.sandboxes:
            raise ValueError(f"Sandbox {sandbox_id} n√£o encontrado")

        sandbox = self.sandboxes[sandbox_id]

        try:
            # Validar permiss√µes
            self.permission_manager.validate_code(code, sandbox["permissions"])

            # Preparar ambiente de execu√ß√£o
            namespace = sandbox["namespace"].copy()
            namespace.update(params)

            # Configurar limites de recursos
            resource.setrlimit(resource.RLIMIT_CPU, (sandbox["resources"]["cpu_seconds"], sandbox["resources"]["cpu_seconds"]))
            resource.setrlimit(resource.RLIMIT_AS, (sandbox["resources"]["memory_bytes"], sandbox["resources"]["memory_bytes"]))

            # Executar com timeout
            with tracer.start_as_current_span("sandbox_execution") as span:
                span.set_attribute("sandbox_id", sandbox_id)

                result = await asyncio.wait_for(
                    self._execute_code(code, namespace),
                    timeout=sandbox["resources"]["timeout_seconds"]
                )

            self.logger.info(
                "sandbox_execution_completed",
                sandbox_id=sandbox_id,
                execution_time=result.get("execution_time", 0)
            )

            return result
        except asyncio.TimeoutError:
            self.logger.warning(
                "sandbox_execution_timeout",
                sandbox_id=sandbox_id
            )
            return {"error": "Execution timeout", "status": "timeout"}
        except Exception as e:
            self.logger.error(
                "sandbox_execution_failed",
                sandbox_id=sandbox_id,
                exc_info=e
            )
            return {"error": str(e), "status": "error"}

    async def destroy(self, sandbox_id: str) -> None:
        """Destr√≥i o ambiente sandbox."""
        if sandbox_id in self.sandboxes:
            del self.sandboxes[sandbox_id]
            self.logger.info(
                "sandbox_destroyed",
                sandbox_id=sandbox_id
            )

    async def _execute_code(self, code: str, namespace: Dict[str, Any]) -> Dict[str, Any]:
        # Implementa√ß√£o da execu√ß√£o de c√≥digo em ambiente restrito
        # ...
```

**Instructions Relacionadas:**
- `api-security.instructions.md`: Princ√≠pios de seguran√ßa
- `observabilidade.instructions.md`: Logging de seguran√ßa

**Prompts Relacionados:**
- `security-analysis.prompt.md`: Para an√°lise de seguran√ßa
- `error-handling.prompt.md`: Para tratamento de erros

### 7. Sistema de Observabilidade para Auto-Extens√£o

**Diret√≥rio:** `src/infrastructure/observability/`
**Arquivos:**
- `auto_extension_metrics.py`
- `auto_extension_traces.py`

**Descri√ß√£o:** Extens√£o do sistema de observabilidade para monitorar especificamente o subsistema de auto-extens√£o, fornecendo m√©tricas, traces e logs detalhados.

**Funcionalidades Principais:**
- M√©tricas espec√≠ficas para gera√ß√£o de tools
- Traces para an√°lise de capacidades
- Logs estruturados de valida√ß√£o
- Alertas para comportamentos an√¥malos

**Exemplo de Implementa√ß√£o:**
```python
from typing import Dict, Any
from prometheus_client import Counter, Histogram, Gauge
from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode

# M√©tricas para sistema de auto-extens√£o
tools_generated = Counter(
    "skyhal_auto_extension_tools_generated_total",
    "Total de tools geradas pelo sistema de auto-extens√£o",
    ["status", "type"]
)

generation_time = Histogram(
    "skyhal_auto_extension_generation_time_seconds",
    "Tempo para gerar uma nova tool",
    ["type"]
)

validation_success_rate = Gauge(
    "skyhal_auto_extension_validation_success_rate",
    "Taxa de sucesso na valida√ß√£o de tools",
    ["type"]
)

sandbox_executions = Counter(
    "skyhal_auto_extension_sandbox_executions_total",
    "Total de execu√ß√µes em ambiente sandbox",
    ["status", "resource_limit"]
)

class AutoExtensionObservability:
    """Configura√ß√£o de observabilidade para o sistema de auto-extens√£o."""

    def __init__(self):
        self.tracer = trace.get_tracer(__name__)
        self.logger = setup_logger(__name__)

    def trace_capability_analysis(self, func):
        """Decorator para tracing de an√°lise de capacidades."""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            with self.tracer.start_as_current_span("capability_analysis") as span:
                try:
                    start_time = time.time()
                    result = await func(*args, **kwargs)

                    # Adicionar atributos ao span
                    span.set_attribute("gaps_found", len(result))
                    span.set_attribute("analysis_time_seconds", time.time() - start_time)
                    span.set_status(Status(StatusCode.OK))

                    return result
                except Exception as e:
                    span.set_status(Status(StatusCode.ERROR))
                    span.record_exception(e)
                    raise
        return wrapper

    def trace_tool_generation(self, func):
        """Decorator para tracing de gera√ß√£o de tools."""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            with self.tracer.start_as_current_span("tool_generation") as span:
                try:
                    spec = kwargs.get("spec") or args[1]  # Assumindo que spec √© segundo argumento
                    span.set_attribute("tool_name", spec.name)
                    span.set_attribute("template_id", spec.template_id)

                    start_time = time.time()
                    tool = await func(*args, **kwargs)
                    elapsed = time.time() - start_time

                    # Registrar m√©tricas
                    tools_generated.labels(
                        status="success",
                        type=spec.template_id
                    ).inc()

                    generation_time.labels(
                        type=spec.template_id
                    ).observe(elapsed)

                    # Atualizar span
                    span.set_attribute("tool_id", tool.tool_id)
                    span.set_attribute("generation_time_seconds", elapsed)
                    span.set_status(Status(StatusCode.OK))

                    return tool
                except Exception as e:
                    tools_generated.labels(
                        status="error",
                        type=kwargs.get("spec", {}).get("template_id", "unknown")
                    ).inc()

                    span.set_status(Status(StatusCode.ERROR))
                    span.record_exception(e)
                    raise
        return wrapper

    def trace_sandbox_execution(self, func):
        """Decorator para tracing de execu√ß√µes sandbox."""
        @wraps(func)
        async def wrapper(*args, **kwargs):
            with self.tracer.start_as_current_span("sandbox_execution") as span:
                try:
                    sandbox_id = kwargs.get("sandbox_id") or args[1]
                    code_hash = hashlib.md5(kwargs.get("code", "").encode()).hexdigest()

                    span.set_attribute("sandbox_id", sandbox_id)
                    span.set_attribute("code_hash", code_hash)

                    start_time = time.time()
                    result = await func(*args, **kwargs)
                    elapsed = time.time() - start_time

                    # Registrar m√©tricas
                    status = result.get("status", "unknown")
                    resource_limit = "none"

                    if status == "timeout":
                        resource_limit = "timeout"
                    elif status == "error" and "memory" in str(result.get("error", "")):
                        resource_limit = "memory"

                    sandbox_executions.labels(
                        status=status,
                        resource_limit=resource_limit
                    ).inc()

                    # Atualizar span
                    span.set_attribute("execution_time_seconds", elapsed)
                    span.set_attribute("execution_status", status)

                    if status == "success":
                        span.set_status(Status(StatusCode.OK))
                    else:
                        span.set_status(Status(StatusCode.ERROR))
                        if "error" in result:
                            span.set_attribute("error_message", str(result["error"]))

                    return result
                except Exception as e:
                    span.set_status(Status(StatusCode.ERROR))
                    span.record_exception(e)

                    sandbox_executions.labels(
                        status="exception",
                        resource_limit="none"
                    ).inc()

                    raise
        return wrapper
```

**Instructions Relacionadas:**
- `observabilidade.instructions.md`: Padr√µes de observabilidade
- `python-mcp.instructions.md`: Integra√ß√£o com OpenTelemetry

**Prompts Relacionados:**
- `observabilidade.prompt.md`: Para implementa√ß√£o de observabilidade

### 8. Documenta√ß√£o de Arquitetura e Uso

**Diret√≥rios:**
- `docs/auto_extension/`
- `docs/especificacoes-tecnicas/artefatos/`

**Arquivos:**
- `architecture.md`
- `security-model.md`
- `usage.md`
- `troubleshooting.md`
- `api-reference.md`

**Descri√ß√£o:** Documenta√ß√£o completa sobre arquitetura, seguran√ßa, uso e troubleshooting do sistema de auto-extens√£o.

**Conte√∫do:**
- Vis√£o geral da arquitetura
- Modelo de seguran√ßa
- Guia de uso e integra√ß√£o
- Troubleshooting e monitoramento
- Refer√™ncia de API
- Casos de uso e exemplos

**Instructions Relacionadas:**
- `documentation.instructions.md`: Padr√µes de documenta√ß√£o
- `troubleshooting.instructions.md`: Guias de troubleshooting

**Prompts Relacionados:**
- `project-planning.prompt.md`: Para documenta√ß√£o estruturada

## üîÑ Fluxos Principais

### 1. Fluxo de An√°lise e Gera√ß√£o

```mermaid
sequenceDiagram
    participant AS as AnalysisService
    participant CA as CapabilityAnalyzer
    participant TS as ToolGenerationService
    participant TG as ToolGenerator
    participant TV as ToolValidator
    participant SB as Sandbox

    AS->>CA: analyze_capabilities()
    CA-->>AS: capability_gaps

    loop For each gap
        AS->>TS: generate_tool_for_gap(gap)
        TS->>TG: generate_tool(spec)
        TG-->>TS: generated_tool

        TS->>TV: validate_tool(generated_tool)
        TV->>SB: create_sandbox()
        SB-->>TV: sandbox_id
        TV->>SB: execute(code, test_cases)
        SB-->>TV: execution_results
        TV-->>TS: validation_report

        alt Validation Passed
            TS->>TS: register_tool(generated_tool)
        else Validation Failed
            TS->>TS: log_failure(validation_report)
        end
    end
```

### 2. Fluxo de Aprendizado

```mermaid
sequenceDiagram
    participant US as UsageService
    participant LS as LearningService
    participant MC as MetricsCollector
    participant PA as PatternAnalyzer
    participant TG as ToolGenerator

    US->>LS: analyze_tool_usage(tool_id)
    LS->>MC: get_tool_metrics(tool_id)
    MC-->>LS: usage_metrics

    LS->>PA: identify_patterns(metrics)
    PA-->>LS: usage_patterns

    LS->>LS: generate_insights(metrics, patterns)

    alt Improvement Needed
        LS->>TG: generate_improved_version(tool_id, insights)
        TG-->>LS: improved_tool
    end
```

## üìä Requisitos de Observabilidade

### M√©tricas a Coletar

1. **M√©tricas de Gera√ß√£o**
   - `skyhal_auto_extension_tools_generated_total` - Contador total de tools geradas
   - `skyhal_auto_extension_generation_time_seconds` - Histograma de tempo de gera√ß√£o
   - `skyhal_auto_extension_validation_success_rate` - Taxa de sucesso na valida√ß√£o

2. **M√©tricas de Execu√ß√£o**
   - `skyhal_auto_extension_sandbox_executions_total` - Contador de execu√ß√µes sandbox
   - `skyhal_auto_extension_sandbox_execution_time_seconds` - Histograma de tempo de execu√ß√£o
   - `skyhal_auto_extension_sandbox_resource_usage` - Uso de recursos por execu√ß√£o

3. **M√©tricas de Aprendizado**
   - `skyhal_auto_extension_learning_insights_total` - Contador de insights gerados
   - `skyhal_auto_extension_tool_improvement_count` - Contador de melhorias por tool

### Traces a Implementar

1. **Traces de An√°lise**
   - Span `capability_analysis` com atributos de gaps encontrados
   - Spans aninhados para cada fase da an√°lise

2. **Traces de Gera√ß√£o**
   - Span `tool_generation` com atributos de especifica√ß√£o
   - Spans aninhados para gera√ß√£o de c√≥digo, valida√ß√£o e testes

3. **Traces de Execu√ß√£o**
   - Span `sandbox_execution` com detalhes de ambiente e recursos

### Logs Estruturados

1. **Logs de Sistema**
   ```python
   logger.info("capability_analysis_completed",
       gaps_found=5,
       severity_avg=0.75,
       analysis_duration_ms=120
   )
   ```

2. **Logs de Seguran√ßa**
   ```python
   logger.warning("sandbox_permission_violation",
       sandbox_id="sandbox-123",
       violation_type="file_access",
       resource="/etc/passwd"
   )
   ```

3. **Logs de Performance**
   ```python
   logger.info("tool_execution_stats",
       tool_id="tool-123",
       execution_time_ms=45,
       memory_usage_mb=128,
       cpu_usage_percent=23
   )
   ```

## üîí Considera√ß√µes de Seguran√ßa

1. **Sandbox Isolado**
   - Isolamento completo de processos
   - Recursos limitados (CPU, mem√≥ria, tempo)
   - Sem acesso a rede por padr√£o
   - Sem acesso ao sistema de arquivos

2. **Valida√ß√£o de C√≥digo**
   - An√°lise est√°tica antes da execu√ß√£o
   - Detec√ß√£o de padr√µes maliciosos
   - Verifica√ß√£o de imports restritos

3. **Sistema de Permiss√µes**
   - Permiss√µes granulares por opera√ß√£o
   - Acesso m√≠nimo necess√°rio
   - Sem permiss√µes permanentes

4. **Mecanismos de Rollback**
   - Versionamento de todas as tools
   - Capacidade de reverter para vers√µes anteriores
   - Estado consistente ap√≥s falhas

5. **Monitoramento Cont√≠nuo**
   - Detec√ß√£o de comportamentos an√¥malos
   - Alertas para tentativas de escape de sandbox
   - Auditoria de todas as opera√ß√µes cr√≠ticas

## üìã Pr√≥ximos Passos

1. **Implementa√ß√£o Inicial**
   - Sistema de an√°lise de capacidades
   - Sandbox b√°sico com isolamento de mem√≥ria
   - Gerador de tools com templates simples

2. **Valida√ß√£o do Conceito**
   - Testes com casos de uso simples
   - Valida√ß√£o de seguran√ßa
   - An√°lise de performance

3. **Evolu√ß√£o**
   - Expandir sistema de aprendizado
   - Adicionar mais templates
   - Melhorar sandbox com isolamento em container

4. **Integra√ß√µes**
   - Conectar com outros subsistemas
   - Ampliar API para uso externo
   - Desenvolver UI para gerenciamento

## üîç Riscos e Mitiga√ß√µes

| Risco | Impacto | Mitiga√ß√£o |
|-------|---------|-----------|
| Execu√ß√£o de c√≥digo malicioso | Alto | Sandbox isolado, valida√ß√£o de c√≥digo, permiss√µes m√≠nimas |
| Uso excessivo de recursos | M√©dio | Quotas, timeouts, monitoramento de recursos |
| Falha na gera√ß√£o de tools √∫teis | M√©dio | Feedback loop, sistema de versionamento, fallback |
| Depend√™ncia de componentes externos | Baixo | Design modular, mocks, testes de integra√ß√£o |
| Complexidade de manuten√ß√£o | M√©dio | Documenta√ß√£o extensiva, testes completos, observabilidade |

## ‚úÖ Crit√©rios de Aceita√ß√£o

- [ ] Sistema de an√°lise de capacidades implementado e testado
- [ ] Gerador de tools funcionando com templates b√°sicos
- [ ] Sandbox de seguran√ßa implementado e validado
- [ ] Sistema de valida√ß√£o de tools funcionando
- [ ] API RESTful para gerenciamento de auto-extens√£o
- [ ] M√©tricas e traces configurados no sistema de observabilidade
- [ ] Documenta√ß√£o t√©cnica completa
- [ ] Cobertura de testes >= 80%
- [ ] Scripts de pre-commit e testes unit√°rios executando sem erros
- [ ] Integra√ß√£o com sistema principal testada e funcionando
